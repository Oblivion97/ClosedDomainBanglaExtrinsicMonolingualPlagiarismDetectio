{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import errno\n",
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Is:  ভালো-মন্দের মধ্য দিয়েই ২০১৯ সাল পার করল বাংলাদেশ। সারা বছর ধরেই নানা আন্তর্জাতিক সংস্থা বিভিন্ন সূচক প্রকাশ করে থাকে। সার্বিকভাবে এসব সূচক দিয়ে বহির্বিশ্বে বাংলাদেশের অবস্থান নির্ধারণ করা হয়। তবে আশঙ্কার বিষয় হলো কিছু সূচকে এত দিন ইতিবাচক ধারায় থাকলেও এখন চ্যালেঞ্জের মুখে পড়ছে। ১৬০ দেশের মধ্যে বাংলাদেশ ১৩৪তম।\n"
     ]
    }
   ],
   "source": [
    "#....test data...\n",
    "f = open(\"doc4.txt\", encoding = 'utf-8')\n",
    "a2 = f.read()\n",
    "\n",
    "print(\"Test Data Is: \",a2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ভালো-মন্দের মধ্য দিয়েই ২০১৯ সাল পার করল বাংলাদেশ'\n",
      " ' সারা বছর ধরেই নানা আন্তর্জাতিক সংস্থা বিভিন্ন সূচক প্রকাশ করে থাকে'\n",
      " ' সার্বিকভাবে এসব সূচক দিয়ে বহির্বিশ্বে বাংলাদেশের অবস্থান নির্ধারণ করা হয়'\n",
      " ' তবে আশঙ্কার বিষয় হলো কিছু সূচকে এত দিন ইতিবাচক ধারায় থাকলেও এখন চ্যালেঞ্জের মুখে পড়ছে'\n",
      " ' ১৬০ দেশের মধ্যে বাংলাদেশ ১৩৪তম' '']\n",
      "['অবস', 'আন', 'আশঙ', 'ইউএনড', 'ইত', 'উন', 'এই', 'এক', 'এখন', 'এগ', 'এত', 'এরপরও', 'এসব', 'কভ', 'কর', 'করল', 'কল', 'গব', 'চক', 'চলত', 'তব', 'তর', 'তহব', 'ধর', 'নব', 'নয়', 'নয়ন', 'পট', 'পড়ছ', 'বছর', 'বহ', 'মধ', 'মন', 'যবধ', 'রক', 'রণ', 'ষম', 'ষয়', 'হল', 'হয়', '১৩৪তম', '১৩৬তম', '১৬০', '১৮৯', '২০১৯']\n"
     ]
    }
   ],
   "source": [
    "sentence2 = a2.split(\"।\")\n",
    "np_sent2 = np.array(sentence2)\n",
    "len_np_sent2 = len(np_sent2)-1\n",
    "\n",
    "#.....create a array for mark text sent is it copy....\n",
    "mark_line = np.zeros(len_np_sent2)\n",
    "print(np_sent2)\n",
    "\n",
    "#......vectorization.........\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(np_sent1)\n",
    "#print(tfidf_matrix_train[:]);\n",
    "print(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Doc iS:  \\doc1.txt\n",
      "Copied Line is: ['ভালো-মন্দের মধ্য দিয়েই ২০১৯ সাল পার করল বাংলাদেশ']\n",
      "Copied Line is: [' সারা বছর ধরেই নানা আন্তর্জাতিক সংস্থা বিভিন্ন সূচক প্রকাশ করে থাকে']\n",
      "No of Lines copied: 2\n",
      "Plagiarism Result is:  40.0 %\n",
      "\n",
      " Train Doc iS:  \\doc2.txt\n",
      "Copied Line is: [' সার্বিকভাবে এসব সূচক দিয়ে বহির্বিশ্বে বাংলাদেশের অবস্থান নির্ধারণ করা হয়']\n",
      "No of Lines copied: 1\n",
      "Plagiarism Result is:  20.0 %\n",
      "\n",
      " Train Doc iS:  \\doc3.txt\n",
      "Copied Line is: [' ১৬০ দেশের মধ্যে বাংলাদেশ ১৩৪তম']\n",
      "No of Lines copied: 1\n",
      "Plagiarism Result is:  20.0 %\n"
     ]
    }
   ],
   "source": [
    "sentence2 = a2.split(\"।\")\n",
    "np_sent2 = np.array(sentence2)\n",
    "len_np_sent2 = len(np_sent2)-1\n",
    "\n",
    "#.....create a array for mark text sent is it copy....\n",
    "mark_line = np.zeros(len_np_sent2)\n",
    "\n",
    "path = 'C:/Users/Adil_Ahnaf/Downloads/Cosine Similarity_V3.1/train data'\n",
    "\n",
    "files=filter(isfile,glob.glob('%s/*'%path))\n",
    "\n",
    "for name in files:\n",
    "        f = open(name, encoding = 'utf-8')\n",
    "        name = str(name).replace('C:/Users/Adil_Ahnaf/Downloads/Cosine Similarity_V3.1/train data', '')\n",
    "        print(\"\\n Train Doc iS: \",name)\n",
    "        a1 = f.read()\n",
    "#         print(a1)\n",
    "        f.close()\n",
    "        \n",
    "        # ......split every sentence & store an array\n",
    "        sentence1 = a1.split(\"।\")\n",
    "        sentence2 = a2.split(\"।\")\n",
    "\n",
    "        # ......store each document in different array\n",
    "        np_sent1 = np.array(sentence1)\n",
    "        np_sent2 = np.array(sentence2)\n",
    "\n",
    "        # ......remove last row for blank line\n",
    "        len_np_sent1 = len(np_sent1)-1\n",
    "        en_np_sent2 = len(np_sent2)-1\n",
    "\n",
    "        #print(len_np_sent1,len_np_sent2)\n",
    "        \n",
    "        #print(\"train data:\", np_sent1)\n",
    "        \n",
    "        np_sent1 = np.delete(np_sent1,len_np_sent1)\n",
    "        np_sent2 = np.delete(np_sent2,len_np_sent2)\n",
    "\n",
    "        # .....store values os np_sent2 in np_sent1\n",
    "        np_sent1 = np.concatenate((np_sent1[:],np_sent2[:]))\n",
    "    \n",
    "        #print(\"mark line:\",mark_line)\n",
    "        #print(\"\\n Total Sentences: \",np_sent1)\n",
    "        #print(len(np_sent1))\n",
    "        \n",
    "        #........vectorize every sentence using TF-IDF\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix_train = tfidf_vectorizer.fit_transform(np_sent1)\n",
    "        #print(tfidf_matrix_train[:]);\n",
    "        \n",
    "        #..........run cosine similarity algorithms.........\n",
    "        flag1 = len_np_sent1\n",
    "        flag2 = flag1 + 1\n",
    "        count_copy = 0\n",
    "        x = 0\n",
    "#         print(flag1,flag2)\n",
    "#        print(\"mark line:\",mark_line)\n",
    "        \n",
    "        while flag1 != len(np_sent1):\n",
    "            cosine_array = np.array(cosine_similarity(tfidf_matrix_train[flag1:flag2], tfidf_matrix_train))\n",
    "            #print(\"cosine scores ==> \",cosine_array)\n",
    "            \n",
    "        #......identify test data sentance index.........\n",
    "#             print(\"Testing index\")\n",
    "#             print(\"falg2\",flag2-1,\"len1\",len_np_sent1-1)\n",
    "#             mark_index = ((flag2-1)-(len_np_sent1-1))-1\n",
    "#             print(\"index is:\" , mark_index)\n",
    "            \n",
    "            flag1 = flag2\n",
    "            flag2 = flag1 + 1\n",
    "            result = cosine_array.flatten()\n",
    "            result = result[:-len_np_sent2]\n",
    "\n",
    "            #.........remove test data result.....\n",
    "\n",
    "#             print(\"length:\",len(result))\n",
    "#             print(\"1D is:\",result)\n",
    "            max_value = np.amax(result)\n",
    "            #print('Max Value from  Array : ', max_value)\n",
    "            if (max_value >= 0.90 and mark_line[x]== 0):\n",
    "                print(\"Copied Line is:\",np_sent1[flag1-1:flag2-1])\n",
    "                mark_line[x] = 1\n",
    "                x = x+1\n",
    "#                 print(\"mark line:\",mark_line,\"\\n\")\n",
    "                count_copy = count_copy + 1\n",
    "            else:\n",
    "                x = x+1 \n",
    "\n",
    "        print(\"No of Lines copied:\" , count_copy)\n",
    "        \n",
    "        #......Calculate  plagiarism in with train doc..........\n",
    "        total_line = len_np_sent2\n",
    "        copied_line = count_copy\n",
    "        plagiarism = (copied_line/total_line)*100\n",
    "        print(\"Plagiarism Result is: \",plagiarism,\"%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#........calculate total plagiarism of test data...........\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Plagiarism Found :  80.0 %\n"
     ]
    }
   ],
   "source": [
    "total_line = len_np_sent2\n",
    "copied_line = 0\n",
    "\n",
    "for x in range(len(mark_line)):\n",
    "    if mark_line[x] == 1:\n",
    "        copied_line = copied_line + 1\n",
    "        \n",
    "plagiarism = (copied_line/total_line)*100\n",
    "print(\"Total Plagiarism Found : \",plagiarism,\"%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
